{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba8daa41",
   "metadata": {},
   "source": [
    "# üìò Day-3 Notes: Generative AI ‚Äì LLMs, LangChain & Fine-tuning\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ Large Language Models (LLMs)\n",
    "\n",
    "**Definition:**\n",
    "\n",
    "* LLM = Large Language Model ‚Üí Trained on massive text datasets, predicts next tokens.\n",
    "* Powerful for tasks like translation, summarization, Q&A, reasoning, coding, etc.\n",
    "\n",
    "### ‚úÖ Key Steps in LLM Development\n",
    "\n",
    "1. **Data Preprocessing & Curation**\n",
    "   * Clean text ‚Üí remove duplicates, noise, sensitive data\n",
    "   * Sources: Internet, Wikipedia, books, research papers, Hugging Face datasets\n",
    "\n",
    "2. **Model Architecture**\n",
    "   * RNN, CNN, Transformers (encoder, decoder, seq2seq)\n",
    "   * Residual connections, normalization, activation functions (ReLU, GELU, Swish), positional embeddings\n",
    "\n",
    "3. **Training**\n",
    "   * Requires **large GPU/TPU infra**\n",
    "   * FLOPs ‚Üë exponentially with parameter size\n",
    "   * Avoid **overfitting** (too large/too long training) and **underfitting** (too small/too short training)\n",
    "\n",
    "4. **Prompt Engineering**\n",
    "   * Zero-shot, few-shot learning, chain-of-thought prompting\n",
    "   * Structured output (JSON, schemas, tools)\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ Fine-tuning LLMs\n",
    "\n",
    "**Definition:** Adapting a pre-trained base model to a specific task/domain.\n",
    "\n",
    "**Steps:**\n",
    "1. Select base model (GPT, LLaMA, T5, etc.)\n",
    "2. Adjust parameters (layers, learning rate, optimizers)\n",
    "3. Train on task-specific dataset\n",
    "\n",
    "**Open-source models that can be fine-tuned:**\n",
    "* Google T5, PaLM\n",
    "* Meta LLaMA (most used)\n",
    "\n",
    "‚ö†Ô∏è Some proprietary models (GPT-3.5, GPT-4, Claude) are **not fine-tunable**.\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ LangChain & Ecosystem\n",
    "\n",
    "**LangChain = Framework for building LLM-powered apps**\n",
    "\n",
    "### üåê Core Components\n",
    "* **LangChain-Core** ‚Üí Base abstractions for LLMs, prompts, memory\n",
    "* **LangChain** ‚Üí Chains, agents, retrieval pipelines\n",
    "* **LangChain-Community** ‚Üí 3rd party integrations\n",
    "* **LangGraph** ‚Üí Orchestration layer (build workflows, agents, persistence)\n",
    "* **LangSmith** ‚Üí Debugging, evaluation, monitoring\n",
    "\n",
    "### üèóÔ∏è LangChain Concepts\n",
    "* **Chat Models** ‚Üí process messages (input: user msg, output: AI msg)\n",
    "* **Memory** ‚Üí save conversation history\n",
    "* **Tools** ‚Üí external APIs, databases, functions\n",
    "* **Vector Stores** ‚Üí store embeddings for retrieval\n",
    "* **Retrieval Augmented Generation (RAG)** ‚Üí combine LLMs with external knowledge\n",
    "* **Streaming** ‚Üí surface results in real-time\n",
    "* **Prompt Templates** ‚Üí reusable prompt structures\n",
    "* **Output Parsers** ‚Üí clean structured outputs (JSON, dicts)\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ LangSmith\n",
    "\n",
    "* Playground ‚Üí test prompts\n",
    "* Debugging poor LLM runs\n",
    "* Annotation, evaluation, monitoring\n",
    "* Prompt optimization\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ Training LLMs ‚Äì Techniques\n",
    "\n",
    "* **Mixed Precision Training** ‚Üí reduce compute cost (16-bit + 32-bit floats)\n",
    "* **Parallelism**:\n",
    "  * Data Parallelism ‚Üí distribute data\n",
    "  * Model Parallelism ‚Üí split large model across GPUs\n",
    "  * Pipeline Parallelism ‚Üí split layers across GPUs\n",
    "  * **3D Parallelism** = combination of all\n",
    "\n",
    "* **ZeRO Optimizer** ‚Üí reduces memory redundancy\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ Key Interview Questions (with short answers)\n",
    "\n",
    "**Q1. What is fine-tuning in LLMs?**  \n",
    "‚û° Adjusting parameters of a pre-trained model for a specific task using smaller task-specific datasets.\n",
    "\n",
    "**Q2. Which models can be fine-tuned?**  \n",
    "‚û° Open-source: LLaMA, T5, PaLM, BERT, Dolly, CTRL. Proprietary (GPT-3.5, GPT-4, Claude) ‚Üí ‚ùå not fine-tunable.\n",
    "\n",
    "**Q3. Why do we need data curation before training LLMs?**  \n",
    "‚û° To remove duplicates, noise, and sensitive data ‚Üí ensures model quality and fairness.\n",
    "\n",
    "**Q4. Difference between Zero-shot and Few-shot prompting?**  \n",
    "‚û° Zero-shot: No examples, only instruction.  \n",
    "‚û° Few-shot: Instruction + a few examples ‚Üí improves accuracy.\n",
    "\n",
    "**Q5. What is Retrieval Augmented Generation (RAG)?**  \n",
    "‚û° Technique combining LLMs with external knowledge bases to improve factual correctness.\n",
    "\n",
    "**Q6. What is LangChain used for?**  \n",
    "‚û° Building LLM-powered apps (chatbots, RAG apps, agents) with modular components (memory, tools, prompts).\n",
    "\n",
    "**Q7. How do you handle hallucinations in LLMs?**  \n",
    "‚û° Use RAG, structured prompting, fine-tuning with domain-specific data, evaluation via LangSmith.\n",
    "\n",
    "**Q8. Why are LLMs called \"large\"?**  \n",
    "‚û° Because of huge **parameters (billions+), dataset size, and compute resources** required.\n",
    "\n",
    "**Q9. What‚Äôs the role of embeddings in LLM apps?**  \n",
    "‚û° Convert text/images into vectors ‚Üí used for similarity search, retrieval, clustering.\n",
    "\n",
    "**Q10. What‚Äôs the difference between Model Parallelism & Data Parallelism?**  \n",
    "‚û° Model parallelism splits the model itself; data parallelism splits the training data.\n",
    "\n",
    "---\n",
    "\n",
    "‚úÖ With this structure, you can revise **in 1‚Äì2 hours before an interview** and still confidently explain everything.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}